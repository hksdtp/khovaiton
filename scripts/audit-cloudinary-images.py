#!/usr/bin/env python3
"""
Script Ä‘á»ƒ kiá»ƒm tra vÃ  rÃ  soÃ¡t táº¥t cáº£ hÃ¬nh áº£nh trong Cloudinary
TÃ¬m cÃ¡c hÃ¬nh áº£nh trÃ¹ng khá»›p, tÆ°Æ¡ng Ä‘á»“ng vÃ  lÃªn káº¿ hoáº¡ch mapping
Äáº·c biá»‡t chÃº Ã½ cÃ¡c file cÃ³ "edited" trong tÃªn
"""

import json
import urllib.request
import urllib.parse
import re
from datetime import datetime
from pathlib import Path
import difflib

# Cloudinary configuration
CLOUDINARY_CLOUD_NAME = 'dgaktc3fb'
CLOUDINARY_API_KEY = '917768158798778'
CLOUDINARY_API_SECRET = 'ZkCVC7alaaSgcnW5kVXYQbxL5uU'

# Supabase configuration
SUPABASE_URL = 'https://zgrfqkytbmahxcbgpkxx.supabase.co'
SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpncmZxa3l0Ym1haHhjYmdwa3h4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDYxNjI1MTAsImV4cCI6MjA2MTczODUxMH0.a6giZZFMrj6jBhLip3ShOFCyTHt5dbe31UDGCECh0Zs'

def cloudinary_request(endpoint, params=None):
    """Thá»±c hiá»‡n request Ä‘áº¿n Cloudinary API"""
    import base64
    
    if params is None:
        params = {}
    
    # Add authentication
    auth_string = f"{CLOUDINARY_API_KEY}:{CLOUDINARY_API_SECRET}"
    auth_bytes = auth_string.encode('ascii')
    auth_b64 = base64.b64encode(auth_bytes).decode('ascii')
    
    # Build URL
    base_url = f"https://api.cloudinary.com/v1_1/{CLOUDINARY_CLOUD_NAME}"
    url = f"{base_url}/{endpoint}"
    
    if params:
        query_string = urllib.parse.urlencode(params)
        url = f"{url}?{query_string}"
    
    headers = {
        'Authorization': f'Basic {auth_b64}',
        'Content-Type': 'application/json'
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req) as response:
            return response.getcode(), response.read().decode('utf-8')
    except urllib.error.HTTPError as e:
        return e.code, e.read().decode('utf-8')
    except Exception as e:
        return 0, str(e)

def get_all_cloudinary_images():
    """Láº¥y táº¥t cáº£ hÃ¬nh áº£nh tá»« Cloudinary"""
    print("ğŸ“¥ Äang láº¥y táº¥t cáº£ hÃ¬nh áº£nh tá»« Cloudinary...")

    all_images = []
    next_cursor = None
    page = 1

    while True:
        print(f"   ğŸ“„ Äang láº¥y trang {page}...")

        params = {
            'type': 'upload',
            'max_results': 500,
            'resource_type': 'image'
        }
        
        if next_cursor:
            params['next_cursor'] = next_cursor
        
        status_code, response = cloudinary_request('resources/image', params)
        
        if status_code != 200:
            print(f"âŒ Lá»—i láº¥y dá»¯ liá»‡u trang {page}: {status_code} - {response}")
            break
        
        try:
            data = json.loads(response)
            images = data.get('resources', [])
            all_images.extend(images)
            
            print(f"   âœ… Trang {page}: {len(images)} hÃ¬nh áº£nh")
            
            next_cursor = data.get('next_cursor')
            if not next_cursor:
                break
                
            page += 1
            
        except Exception as e:
            print(f"âŒ Lá»—i parse response trang {page}: {e}")
            break
    
    print(f"âœ… ÄÃ£ láº¥y tá»•ng cá»™ng {len(all_images)} hÃ¬nh áº£nh tá»« Cloudinary")
    return all_images

def supabase_request(method, endpoint, data=None):
    """Thá»±c hiá»‡n request Ä‘áº¿n Supabase API"""
    url = f"{SUPABASE_URL}/rest/v1/{endpoint}"
    
    headers = {
        'apikey': SUPABASE_ANON_KEY,
        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',
        'Content-Type': 'application/json'
    }
    
    try:
        if data:
            data_bytes = json.dumps(data).encode('utf-8')
            req = urllib.request.Request(url, data=data_bytes, headers=headers, method=method)
        else:
            req = urllib.request.Request(url, headers=headers, method=method)
        
        with urllib.request.urlopen(req) as response:
            return response.getcode(), response.read().decode('utf-8')
            
    except urllib.error.HTTPError as e:
        return e.code, e.read().decode('utf-8')
    except Exception as e:
        return 0, str(e)

def get_all_fabric_codes():
    """Láº¥y táº¥t cáº£ mÃ£ váº£i tá»« database"""
    print("ğŸ“¥ Äang láº¥y táº¥t cáº£ mÃ£ váº£i tá»« database...")
    
    status_code, response = supabase_request('GET', 'fabrics?select=code,name,image')
    
    if status_code == 200:
        try:
            fabrics = json.loads(response)
            print(f"âœ… ÄÃ£ láº¥y {len(fabrics)} mÃ£ váº£i tá»« database")
            return fabrics
        except Exception as e:
            print(f"âŒ Lá»—i parse response: {e}")
            return []
    else:
        print(f"âŒ Lá»—i láº¥y dá»¯ liá»‡u: {status_code} - {response}")
        return []

def extract_fabric_code_from_filename(filename):
    """TrÃ­ch xuáº¥t mÃ£ váº£i tá»« tÃªn file"""
    # Loáº¡i bá» extension vÃ  prefix
    name = filename.replace('fabric_images/', '').replace('.jpg', '').replace('.png', '').replace('.jpeg', '')
    
    # Loáº¡i bá» cÃ¡c suffix nhÆ° _edited, _copy, _v2, etc
    name = re.sub(r'_edited.*$', '', name, flags=re.IGNORECASE)
    name = re.sub(r'_copy.*$', '', name, flags=re.IGNORECASE)
    name = re.sub(r'_v\d+.*$', '', name, flags=re.IGNORECASE)
    name = re.sub(r'_\d+$', '', name)
    
    return name.strip()

def normalize_code(code):
    """Chuáº©n hÃ³a mÃ£ Ä‘á»ƒ so sÃ¡nh"""
    if not code:
        return ""
    
    # Chuyá»ƒn vá» uppercase vÃ  loáº¡i bá» khoáº£ng tráº¯ng
    normalized = str(code).upper().strip()
    
    # Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t
    normalized = re.sub(r'[^\w\-]', '', normalized)
    
    return normalized

def find_similar_codes(code, all_codes, threshold=0.8):
    """TÃ¬m cÃ¡c mÃ£ tÆ°Æ¡ng Ä‘á»“ng"""
    similar = []
    normalized_code = normalize_code(code)
    
    for other_code in all_codes:
        normalized_other = normalize_code(other_code)
        
        if normalized_code == normalized_other:
            continue
        
        # Sá»­ dá»¥ng difflib Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
        similarity = difflib.SequenceMatcher(None, normalized_code, normalized_other).ratio()
        
        if similarity >= threshold:
            similar.append({
                'code': other_code,
                'similarity': similarity
            })
    
    return sorted(similar, key=lambda x: x['similarity'], reverse=True)

def analyze_cloudinary_images(images, fabrics):
    """PhÃ¢n tÃ­ch hÃ¬nh áº£nh Cloudinary"""
    print("ğŸ” Äang phÃ¢n tÃ­ch hÃ¬nh áº£nh Cloudinary...")
    
    # Táº¡o danh sÃ¡ch mÃ£ váº£i tá»« database
    fabric_codes = [f['code'] for f in fabrics]
    fabric_dict = {normalize_code(f['code']): f for f in fabrics}
    
    analysis = {
        'total_images': len(images),
        'exact_matches': [],
        'similar_matches': [],
        'edited_images': [],
        'unmapped_images': [],
        'duplicate_codes': {},
        'fabric_without_images': []
    }
    
    # PhÃ¢n tÃ­ch tá»«ng hÃ¬nh áº£nh
    for img in images:
        public_id = img.get('public_id', '')
        display_name = img.get('display_name', public_id)
        filename = public_id.split('/')[-1] if '/' in public_id else public_id
        
        # TrÃ­ch xuáº¥t mÃ£ váº£i tá»« filename
        extracted_code = extract_fabric_code_from_filename(public_id)
        normalized_extracted = normalize_code(extracted_code)
        
        # Kiá»ƒm tra edited images
        if 'edited' in display_name.lower() or 'edited' in public_id.lower():
            analysis['edited_images'].append({
                'public_id': public_id,
                'display_name': display_name,
                'extracted_code': extracted_code,
                'url': img.get('secure_url', ''),
                'created_at': img.get('created_at', ''),
                'bytes': img.get('bytes', 0)
            })
        
        # TÃ¬m exact match
        exact_match = None
        for fabric in fabrics:
            if normalize_code(fabric['code']) == normalized_extracted:
                exact_match = fabric
                break
        
        if exact_match:
            analysis['exact_matches'].append({
                'image': {
                    'public_id': public_id,
                    'display_name': display_name,
                    'url': img.get('secure_url', ''),
                    'extracted_code': extracted_code
                },
                'fabric': exact_match,
                'has_existing_image': bool(exact_match.get('image'))
            })
        else:
            # TÃ¬m similar matches
            similar = find_similar_codes(extracted_code, fabric_codes, threshold=0.7)
            
            if similar:
                analysis['similar_matches'].append({
                    'image': {
                        'public_id': public_id,
                        'display_name': display_name,
                        'url': img.get('secure_url', ''),
                        'extracted_code': extracted_code
                    },
                    'similar_fabrics': similar[:5]  # Top 5 similar
                })
            else:
                analysis['unmapped_images'].append({
                    'public_id': public_id,
                    'display_name': display_name,
                    'url': img.get('secure_url', ''),
                    'extracted_code': extracted_code
                })
        
        # Kiá»ƒm tra duplicate codes
        if normalized_extracted in analysis['duplicate_codes']:
            analysis['duplicate_codes'][normalized_extracted].append({
                'public_id': public_id,
                'display_name': display_name,
                'url': img.get('secure_url', '')
            })
        else:
            analysis['duplicate_codes'][normalized_extracted] = [{
                'public_id': public_id,
                'display_name': display_name,
                'url': img.get('secure_url', '')
            }]
    
    # Loáº¡i bá» codes khÃ´ng cÃ³ duplicate
    analysis['duplicate_codes'] = {k: v for k, v in analysis['duplicate_codes'].items() if len(v) > 1}
    
    # TÃ¬m fabrics khÃ´ng cÃ³ hÃ¬nh áº£nh
    mapped_codes = set()
    for match in analysis['exact_matches']:
        mapped_codes.add(normalize_code(match['fabric']['code']))
    
    for fabric in fabrics:
        normalized_code = normalize_code(fabric['code'])
        if normalized_code not in mapped_codes and not fabric.get('image'):
            analysis['fabric_without_images'].append(fabric)
    
    return analysis

def create_detailed_report(analysis, images, fabrics):
    """Táº¡o bÃ¡o cÃ¡o chi tiáº¿t"""
    
    report_content = f"""# ğŸ“Š BÃO CÃO RÃ€ SOÃT HÃŒNH áº¢NH CLOUDINARY

## ğŸ“ˆ Tá»•ng quan:
- **Tá»•ng hÃ¬nh áº£nh trong Cloudinary:** {analysis['total_images']}
- **Tá»•ng sáº£n pháº©m trong database:** {len(fabrics)}
- **Exact matches:** {len(analysis['exact_matches'])}
- **Similar matches:** {len(analysis['similar_matches'])}
- **HÃ¬nh áº£nh cÃ³ "edited":** {len(analysis['edited_images'])}
- **HÃ¬nh áº£nh chÆ°a map:** {len(analysis['unmapped_images'])}
- **MÃ£ trÃ¹ng láº·p:** {len(analysis['duplicate_codes'])}
- **Sáº£n pháº©m chÆ°a cÃ³ hÃ¬nh:** {len(analysis['fabric_without_images'])}

## ğŸ¯ EXACT MATCHES ({len(analysis['exact_matches'])})
CÃ¡c hÃ¬nh áº£nh khá»›p chÃ­nh xÃ¡c vá»›i mÃ£ sáº£n pháº©m:

"""
    
    for i, match in enumerate(analysis['exact_matches'][:20], 1):
        status = "âœ… ÄÃ£ cÃ³ hÃ¬nh" if match['has_existing_image'] else "ğŸ†• ChÆ°a cÃ³ hÃ¬nh"
        report_content += f"{i}. **{match['fabric']['code']}** - {match['fabric']['name'][:50]}...\n"
        report_content += f"   ğŸ“· {match['image']['display_name']} ({status})\n"
        report_content += f"   ğŸ”— {match['image']['url']}\n\n"
    
    if len(analysis['exact_matches']) > 20:
        report_content += f"... vÃ  {len(analysis['exact_matches']) - 20} matches khÃ¡c\n\n"
    
    # Edited images
    if analysis['edited_images']:
        report_content += f"""## âœï¸ HÃŒNH áº¢NH CÃ“ "EDITED" ({len(analysis['edited_images'])})
CÃ¡c hÃ¬nh áº£nh cÃ³ tá»« "edited" trong tÃªn - cáº§n xem xÃ©t Æ°u tiÃªn:

"""
        for i, img in enumerate(analysis['edited_images'][:15], 1):
            report_content += f"{i}. **{img['display_name']}**\n"
            report_content += f"   ğŸ“ MÃ£ trÃ­ch xuáº¥t: {img['extracted_code']}\n"
            report_content += f"   ğŸ”— {img['url']}\n"
            report_content += f"   ğŸ“… {img['created_at']}\n\n"
        
        if len(analysis['edited_images']) > 15:
            report_content += f"... vÃ  {len(analysis['edited_images']) - 15} hÃ¬nh edited khÃ¡c\n\n"
    
    # Similar matches
    if analysis['similar_matches']:
        report_content += f"""## ğŸ” SIMILAR MATCHES ({len(analysis['similar_matches'])})
CÃ¡c hÃ¬nh áº£nh cÃ³ mÃ£ tÆ°Æ¡ng Ä‘á»“ng vá»›i sáº£n pháº©m:

"""
        for i, match in enumerate(analysis['similar_matches'][:10], 1):
            report_content += f"{i}. **{match['image']['extracted_code']}** ({match['image']['display_name']})\n"
            report_content += f"   ğŸ¯ CÃ³ thá»ƒ khá»›p vá»›i:\n"
            for similar in match['similar_fabrics'][:3]:
                report_content += f"      â€¢ {similar['code']} (Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng: {similar['similarity']:.1%})\n"
            report_content += f"   ğŸ”— {match['image']['url']}\n\n"
    
    # Duplicate codes
    if analysis['duplicate_codes']:
        report_content += f"""## ğŸ”„ MÃƒ TRÃ™NG Láº¶P ({len(analysis['duplicate_codes'])})
CÃ¡c mÃ£ cÃ³ nhiá»u hÃ¬nh áº£nh:

"""
        for code, images_list in list(analysis['duplicate_codes'].items())[:10]:
            report_content += f"**{code}** ({len(images_list)} hÃ¬nh áº£nh):\n"
            for img in images_list:
                report_content += f"   â€¢ {img['display_name']}\n"
                report_content += f"     ğŸ”— {img['url']}\n"
            report_content += "\n"
    
    # Unmapped images
    if analysis['unmapped_images']:
        report_content += f"""## â“ HÃŒNH áº¢NH CHÆ¯A MAP ({len(analysis['unmapped_images'])})
CÃ¡c hÃ¬nh áº£nh khÃ´ng khá»›p vá»›i sáº£n pháº©m nÃ o:

"""
        for i, img in enumerate(analysis['unmapped_images'][:15], 1):
            report_content += f"{i}. **{img['display_name']}**\n"
            report_content += f"   ğŸ“ MÃ£ trÃ­ch xuáº¥t: {img['extracted_code']}\n"
            report_content += f"   ğŸ”— {img['url']}\n\n"
    
    # Fabrics without images
    report_content += f"""## ğŸ“· Sáº¢N PHáº¨M CHÆ¯A CÃ“ HÃŒNH ({len(analysis['fabric_without_images'])})
CÃ¡c sáº£n pháº©m trong database chÆ°a cÃ³ hÃ¬nh áº£nh:

"""
    for i, fabric in enumerate(analysis['fabric_without_images'][:20], 1):
        report_content += f"{i}. **{fabric['code']}** - {fabric['name'][:50]}...\n"
    
    if len(analysis['fabric_without_images']) > 20:
        report_content += f"... vÃ  {len(analysis['fabric_without_images']) - 20} sáº£n pháº©m khÃ¡c\n"
    
    report_content += f"""

## ğŸ“‹ Káº¾ HOáº CH MAPPING

### ğŸ¯ Æ¯u tiÃªn 1: Exact Matches
- **{len([m for m in analysis['exact_matches'] if not m['has_existing_image']])} sáº£n pháº©m** cÃ³ hÃ¬nh exact match nhÆ°ng chÆ°a Ä‘Æ°á»£c map
- **HÃ nh Ä‘á»™ng:** Tá»± Ä‘á»™ng map ngay láº­p tá»©c

### âœï¸ Æ¯u tiÃªn 2: HÃ¬nh áº£nh Edited
- **{len(analysis['edited_images'])} hÃ¬nh áº£nh** cÃ³ "edited" trong tÃªn
- **HÃ nh Ä‘á»™ng:** Xem xÃ©t thá»§ cÃ´ng, cÃ³ thá»ƒ lÃ  phiÃªn báº£n cáº£i tiáº¿n

### ğŸ” Æ¯u tiÃªn 3: Similar Matches
- **{len(analysis['similar_matches'])} hÃ¬nh áº£nh** cÃ³ mÃ£ tÆ°Æ¡ng Ä‘á»“ng
- **HÃ nh Ä‘á»™ng:** Xem xÃ©t thá»§ cÃ´ng Ä‘á»ƒ xÃ¡c nháº­n mapping

### ğŸ”„ Æ¯u tiÃªn 4: Duplicate Codes
- **{len(analysis['duplicate_codes'])} mÃ£** cÃ³ nhiá»u hÃ¬nh áº£nh
- **HÃ nh Ä‘á»™ng:** Chá»n hÃ¬nh áº£nh tá»‘t nháº¥t (Æ°u tiÃªn edited version)

### ğŸ“· Æ¯u tiÃªn 5: Upload má»›i
- **{len(analysis['fabric_without_images'])} sáº£n pháº©m** chÆ°a cÃ³ hÃ¬nh áº£nh
- **HÃ nh Ä‘á»™ng:** Cáº§n chá»¥p/upload hÃ¬nh áº£nh má»›i

## ğŸ“Š Thá»‘ng kÃª mapping hiá»‡n táº¡i:
- **ÄÃ£ cÃ³ hÃ¬nh:** {len([f for f in fabrics if f.get('image')])} sáº£n pháº©m
- **ChÆ°a cÃ³ hÃ¬nh:** {len([f for f in fabrics if not f.get('image')])} sáº£n pháº©m
- **Tá»· lá»‡ cÃ³ hÃ¬nh:** {len([f for f in fabrics if f.get('image')])/len(fabrics)*100:.1f}%

---
Táº¡o bá»Ÿi: audit-cloudinary-images.py
Thá»i gian: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
"""
    
    return report_content

def save_detailed_data(analysis, images, fabrics):
    """LÆ°u dá»¯ liá»‡u chi tiáº¿t Ä‘á»ƒ xá»­ lÃ½ sau"""
    
    # LÆ°u analysis data
    analysis_data = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_images': analysis['total_images'],
            'total_fabrics': len(fabrics),
            'exact_matches': len(analysis['exact_matches']),
            'similar_matches': len(analysis['similar_matches']),
            'edited_images': len(analysis['edited_images']),
            'unmapped_images': len(analysis['unmapped_images']),
            'duplicate_codes': len(analysis['duplicate_codes']),
            'fabric_without_images': len(analysis['fabric_without_images'])
        },
        'analysis': analysis
    }
    
    with open('cloudinary-audit-analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, ensure_ascii=False, indent=2)
    
    print("ğŸ’¾ ÄÃ£ lÆ°u dá»¯ liá»‡u chi tiáº¿t: cloudinary-audit-analysis.json")

def main():
    print("ğŸš€ Báº®T Äáº¦U RÃ€ SOÃT HÃŒNH áº¢NH CLOUDINARY")
    print("="*60)
    
    # 1. Láº¥y táº¥t cáº£ hÃ¬nh áº£nh tá»« Cloudinary
    images = get_all_cloudinary_images()
    if not images:
        print("âŒ KhÃ´ng cÃ³ hÃ¬nh áº£nh Ä‘á»ƒ phÃ¢n tÃ­ch")
        return
    
    # 2. Láº¥y táº¥t cáº£ mÃ£ váº£i tá»« database
    fabrics = get_all_fabric_codes()
    if not fabrics:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u fabric Ä‘á»ƒ so sÃ¡nh")
        return
    
    # 3. PhÃ¢n tÃ­ch hÃ¬nh áº£nh
    analysis = analyze_cloudinary_images(images, fabrics)
    
    # 4. Táº¡o bÃ¡o cÃ¡o
    report = create_detailed_report(analysis, images, fabrics)
    
    with open('BAO_CAO_RA_SOAT_CLOUDINARY.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    # 5. LÆ°u dá»¯ liá»‡u chi tiáº¿t
    save_detailed_data(analysis, images, fabrics)
    
    print(f"\nğŸ‰ HOÃ€N Táº¤T RÃ€ SOÃT!")
    print(f"ğŸ“Š Tá»•ng káº¿t:")
    print(f"   ğŸ“· Tá»•ng hÃ¬nh áº£nh: {analysis['total_images']}")
    print(f"   âœ… Exact matches: {len(analysis['exact_matches'])}")
    print(f"   âœï¸ HÃ¬nh edited: {len(analysis['edited_images'])}")
    print(f"   ğŸ” Similar matches: {len(analysis['similar_matches'])}")
    print(f"   ğŸ”„ MÃ£ trÃ¹ng láº·p: {len(analysis['duplicate_codes'])}")
    print(f"   â“ ChÆ°a map: {len(analysis['unmapped_images'])}")
    print(f"   ğŸ“· Sáº£n pháº©m chÆ°a cÃ³ hÃ¬nh: {len(analysis['fabric_without_images'])}")
    
    print(f"\nğŸ“ Files Ä‘Ã£ táº¡o:")
    print(f"   ğŸ“‹ BAO_CAO_RA_SOAT_CLOUDINARY.md - BÃ¡o cÃ¡o chi tiáº¿t")
    print(f"   ğŸ’¾ cloudinary-audit-analysis.json - Dá»¯ liá»‡u phÃ¢n tÃ­ch")

if __name__ == "__main__":
    main()
