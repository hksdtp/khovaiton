#!/usr/bin/env python3
"""
Script ƒë·ªÉ ki·ªÉm tra v√† r√† so√°t t·∫•t c·∫£ h√¨nh ·∫£nh trong Cloudinary
T√¨m c√°c h√¨nh ·∫£nh tr√πng kh·ªõp, t∆∞∆°ng ƒë·ªìng v√† l√™n k·∫ø ho·∫°ch mapping
ƒê·∫∑c bi·ªát ch√∫ √Ω c√°c file c√≥ "edited" trong t√™n
"""

import json
import urllib.request
import urllib.parse
import re
from datetime import datetime
from pathlib import Path
import difflib

# Cloudinary configuration
CLOUDINARY_CLOUD_NAME = 'dgaktc3fb'
CLOUDINARY_API_KEY = '917768158798778'
CLOUDINARY_API_SECRET = 'ZkCVC7alaaSgcnW5kVXYQbxL5uU'

# Supabase configuration
SUPABASE_URL = 'https://zgrfqkytbmahxcbgpkxx.supabase.co'
SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpncmZxa3l0Ym1haHhjYmdwa3h4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDYxNjI1MTAsImV4cCI6MjA2MTczODUxMH0.a6giZZFMrj6jBhLip3ShOFCyTHt5dbe31UDGCECh0Zs'

def cloudinary_request(endpoint, params=None):
    """Th·ª±c hi·ªán request ƒë·∫øn Cloudinary API"""
    import base64
    
    if params is None:
        params = {}
    
    # Add authentication
    auth_string = f"{CLOUDINARY_API_KEY}:{CLOUDINARY_API_SECRET}"
    auth_bytes = auth_string.encode('ascii')
    auth_b64 = base64.b64encode(auth_bytes).decode('ascii')
    
    # Build URL
    base_url = f"https://api.cloudinary.com/v1_1/{CLOUDINARY_CLOUD_NAME}"
    url = f"{base_url}/{endpoint}"
    
    if params:
        query_string = urllib.parse.urlencode(params)
        url = f"{url}?{query_string}"
    
    headers = {
        'Authorization': f'Basic {auth_b64}',
        'Content-Type': 'application/json'
    }
    
    try:
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req) as response:
            return response.getcode(), response.read().decode('utf-8')
    except urllib.error.HTTPError as e:
        return e.code, e.read().decode('utf-8')
    except Exception as e:
        return 0, str(e)

def get_all_cloudinary_images():
    """L·∫•y t·∫•t c·∫£ h√¨nh ·∫£nh t·ª´ Cloudinary"""
    print("üì• ƒêang l·∫•y t·∫•t c·∫£ h√¨nh ·∫£nh t·ª´ Cloudinary...")

    all_images = []
    next_cursor = None
    page = 1

    while True:
        print(f"   üìÑ ƒêang l·∫•y trang {page}...")

        params = {
            'type': 'upload',
            'max_results': 500,
            'resource_type': 'image'
        }
        
        if next_cursor:
            params['next_cursor'] = next_cursor
        
        status_code, response = cloudinary_request('resources/image', params)
        
        if status_code != 200:
            print(f"‚ùå L·ªói l·∫•y d·ªØ li·ªáu trang {page}: {status_code} - {response}")
            break
        
        try:
            data = json.loads(response)
            images = data.get('resources', [])
            all_images.extend(images)
            
            print(f"   ‚úÖ Trang {page}: {len(images)} h√¨nh ·∫£nh")
            
            next_cursor = data.get('next_cursor')
            if not next_cursor:
                break
                
            page += 1
            
        except Exception as e:
            print(f"‚ùå L·ªói parse response trang {page}: {e}")
            break
    
    print(f"‚úÖ ƒê√£ l·∫•y t·ªïng c·ªông {len(all_images)} h√¨nh ·∫£nh t·ª´ Cloudinary")
    return all_images

def supabase_request(method, endpoint, data=None):
    """Th·ª±c hi·ªán request ƒë·∫øn Supabase API"""
    url = f"{SUPABASE_URL}/rest/v1/{endpoint}"
    
    headers = {
        'apikey': SUPABASE_ANON_KEY,
        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',
        'Content-Type': 'application/json'
    }
    
    try:
        if data:
            data_bytes = json.dumps(data).encode('utf-8')
            req = urllib.request.Request(url, data=data_bytes, headers=headers, method=method)
        else:
            req = urllib.request.Request(url, headers=headers, method=method)
        
        with urllib.request.urlopen(req) as response:
            return response.getcode(), response.read().decode('utf-8')
            
    except urllib.error.HTTPError as e:
        return e.code, e.read().decode('utf-8')
    except Exception as e:
        return 0, str(e)

def get_all_fabric_codes():
    """L·∫•y t·∫•t c·∫£ m√£ v·∫£i t·ª´ database"""
    print("üì• ƒêang l·∫•y t·∫•t c·∫£ m√£ v·∫£i t·ª´ database...")
    
    status_code, response = supabase_request('GET', 'fabrics?select=code,name,image')
    
    if status_code == 200:
        try:
            fabrics = json.loads(response)
            print(f"‚úÖ ƒê√£ l·∫•y {len(fabrics)} m√£ v·∫£i t·ª´ database")
            return fabrics
        except Exception as e:
            print(f"‚ùå L·ªói parse response: {e}")
            return []
    else:
        print(f"‚ùå L·ªói l·∫•y d·ªØ li·ªáu: {status_code} - {response}")
        return []

def extract_fabric_code_from_filename(filename):
    """Tr√≠ch xu·∫•t m√£ v·∫£i t·ª´ t√™n file"""
    # Lo·∫°i b·ªè extension v√† prefix
    name = filename.replace('fabric_images/', '').replace('.jpg', '').replace('.png', '').replace('.jpeg', '')
    
    # Lo·∫°i b·ªè c√°c suffix nh∆∞ _edited, _copy, _v2, etc
    name = re.sub(r'_edited.*$', '', name, flags=re.IGNORECASE)
    name = re.sub(r'_copy.*$', '', name, flags=re.IGNORECASE)
    name = re.sub(r'_v\d+.*$', '', name, flags=re.IGNORECASE)
    name = re.sub(r'_\d+$', '', name)
    
    return name.strip()

def normalize_code(code):
    """Chu·∫©n h√≥a m√£ ƒë·ªÉ so s√°nh"""
    if not code:
        return ""
    
    # Chuy·ªÉn v·ªÅ uppercase v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng
    normalized = str(code).upper().strip()
    
    # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát
    normalized = re.sub(r'[^\w\-]', '', normalized)
    
    return normalized

def find_similar_codes(code, all_codes, threshold=0.8):
    """T√¨m c√°c m√£ t∆∞∆°ng ƒë·ªìng"""
    similar = []
    normalized_code = normalize_code(code)
    
    for other_code in all_codes:
        normalized_other = normalize_code(other_code)
        
        if normalized_code == normalized_other:
            continue
        
        # S·ª≠ d·ª•ng difflib ƒë·ªÉ t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
        similarity = difflib.SequenceMatcher(None, normalized_code, normalized_other).ratio()
        
        if similarity >= threshold:
            similar.append({
                'code': other_code,
                'similarity': similarity
            })
    
    return sorted(similar, key=lambda x: x['similarity'], reverse=True)

def analyze_cloudinary_images(images, fabrics):
    """Ph√¢n t√≠ch h√¨nh ·∫£nh Cloudinary"""
    print("üîç ƒêang ph√¢n t√≠ch h√¨nh ·∫£nh Cloudinary...")
    
    # T·∫°o danh s√°ch m√£ v·∫£i t·ª´ database
    fabric_codes = [f['code'] for f in fabrics]
    fabric_dict = {normalize_code(f['code']): f for f in fabrics}
    
    analysis = {
        'total_images': len(images),
        'exact_matches': [],
        'similar_matches': [],
        'edited_images': [],
        'unmapped_images': [],
        'duplicate_codes': {},
        'fabric_without_images': []
    }
    
    # Ph√¢n t√≠ch t·ª´ng h√¨nh ·∫£nh
    for img in images:
        public_id = img.get('public_id', '')
        display_name = img.get('display_name', public_id)
        filename = public_id.split('/')[-1] if '/' in public_id else public_id
        
        # Tr√≠ch xu·∫•t m√£ v·∫£i t·ª´ filename
        extracted_code = extract_fabric_code_from_filename(public_id)
        normalized_extracted = normalize_code(extracted_code)
        
        # Ki·ªÉm tra edited images
        if 'edited' in display_name.lower() or 'edited' in public_id.lower():
            analysis['edited_images'].append({
                'public_id': public_id,
                'display_name': display_name,
                'extracted_code': extracted_code,
                'url': img.get('secure_url', ''),
                'created_at': img.get('created_at', ''),
                'bytes': img.get('bytes', 0)
            })
        
        # T√¨m exact match
        exact_match = None
        for fabric in fabrics:
            if normalize_code(fabric['code']) == normalized_extracted:
                exact_match = fabric
                break
        
        if exact_match:
            analysis['exact_matches'].append({
                'image': {
                    'public_id': public_id,
                    'display_name': display_name,
                    'url': img.get('secure_url', ''),
                    'extracted_code': extracted_code
                },
                'fabric': exact_match,
                'has_existing_image': bool(exact_match.get('image'))
            })
        else:
            # T√¨m similar matches
            similar = find_similar_codes(extracted_code, fabric_codes, threshold=0.7)
            
            if similar:
                analysis['similar_matches'].append({
                    'image': {
                        'public_id': public_id,
                        'display_name': display_name,
                        'url': img.get('secure_url', ''),
                        'extracted_code': extracted_code
                    },
                    'similar_fabrics': similar[:5]  # Top 5 similar
                })
            else:
                analysis['unmapped_images'].append({
                    'public_id': public_id,
                    'display_name': display_name,
                    'url': img.get('secure_url', ''),
                    'extracted_code': extracted_code
                })
        
        # Ki·ªÉm tra duplicate codes
        if normalized_extracted in analysis['duplicate_codes']:
            analysis['duplicate_codes'][normalized_extracted].append({
                'public_id': public_id,
                'display_name': display_name,
                'url': img.get('secure_url', '')
            })
        else:
            analysis['duplicate_codes'][normalized_extracted] = [{
                'public_id': public_id,
                'display_name': display_name,
                'url': img.get('secure_url', '')
            }]
    
    # Lo·∫°i b·ªè codes kh√¥ng c√≥ duplicate
    analysis['duplicate_codes'] = {k: v for k, v in analysis['duplicate_codes'].items() if len(v) > 1}
    
    # T√¨m fabrics kh√¥ng c√≥ h√¨nh ·∫£nh
    mapped_codes = set()
    for match in analysis['exact_matches']:
        mapped_codes.add(normalize_code(match['fabric']['code']))
    
    for fabric in fabrics:
        normalized_code = normalize_code(fabric['code'])
        if normalized_code not in mapped_codes and not fabric.get('image'):
            analysis['fabric_without_images'].append(fabric)
    
    return analysis

def create_detailed_report(analysis, images, fabrics):
    """T·∫°o b√°o c√°o chi ti·∫øt"""
    
    report_content = f"""# üìä B√ÅO C√ÅO R√Ä SO√ÅT H√åNH ·∫¢NH CLOUDINARY

## üìà T·ªïng quan:
- **T·ªïng h√¨nh ·∫£nh trong Cloudinary:** {analysis['total_images']}
- **T·ªïng s·∫£n ph·∫©m trong database:** {len(fabrics)}
- **Exact matches:** {len(analysis['exact_matches'])}
- **Similar matches:** {len(analysis['similar_matches'])}
- **H√¨nh ·∫£nh c√≥ "edited":** {len(analysis['edited_images'])}
- **H√¨nh ·∫£nh ch∆∞a map:** {len(analysis['unmapped_images'])}
- **M√£ tr√πng l·∫∑p:** {len(analysis['duplicate_codes'])}
- **S·∫£n ph·∫©m ch∆∞a c√≥ h√¨nh:** {len(analysis['fabric_without_images'])}

## üéØ EXACT MATCHES ({len(analysis['exact_matches'])})
C√°c h√¨nh ·∫£nh kh·ªõp ch√≠nh x√°c v·ªõi m√£ s·∫£n ph·∫©m:

"""
    
    for i, match in enumerate(analysis['exact_matches'][:20], 1):
        status = "‚úÖ ƒê√£ c√≥ h√¨nh" if match['has_existing_image'] else "üÜï Ch∆∞a c√≥ h√¨nh"
        report_content += f"{i}. **{match['fabric']['code']}** - {match['fabric']['name'][:50]}...\n"
        report_content += f"   üì∑ {match['image']['display_name']} ({status})\n"
        report_content += f"   üîó {match['image']['url']}\n\n"
    
    if len(analysis['exact_matches']) > 20:
        report_content += f"... v√† {len(analysis['exact_matches']) - 20} matches kh√°c\n\n"
    
    # Edited images
    if analysis['edited_images']:
        report_content += f"""## ‚úèÔ∏è H√åNH ·∫¢NH C√ì "EDITED" ({len(analysis['edited_images'])})
C√°c h√¨nh ·∫£nh c√≥ t·ª´ "edited" trong t√™n - c·∫ßn xem x√©t ∆∞u ti√™n:

"""
        for i, img in enumerate(analysis['edited_images'][:15], 1):
            report_content += f"{i}. **{img['display_name']}**\n"
            report_content += f"   üìù M√£ tr√≠ch xu·∫•t: {img['extracted_code']}\n"
            report_content += f"   üîó {img['url']}\n"
            report_content += f"   üìÖ {img['created_at']}\n\n"
        
        if len(analysis['edited_images']) > 15:
            report_content += f"... v√† {len(analysis['edited_images']) - 15} h√¨nh edited kh√°c\n\n"
    
    # Similar matches
    if analysis['similar_matches']:
        report_content += f"""## üîç SIMILAR MATCHES ({len(analysis['similar_matches'])})
C√°c h√¨nh ·∫£nh c√≥ m√£ t∆∞∆°ng ƒë·ªìng v·ªõi s·∫£n ph·∫©m:

"""
        for i, match in enumerate(analysis['similar_matches'][:10], 1):
            report_content += f"{i}. **{match['image']['extracted_code']}** ({match['image']['display_name']})\n"
            report_content += f"   üéØ C√≥ th·ªÉ kh·ªõp v·ªõi:\n"
            for similar in match['similar_fabrics'][:3]:
                report_content += f"      ‚Ä¢ {similar['code']} (ƒë·ªô t∆∞∆°ng ƒë·ªìng: {similar['similarity']:.1%})\n"
            report_content += f"   üîó {match['image']['url']}\n\n"
    
    # Duplicate codes
    if analysis['duplicate_codes']:
        report_content += f"""## üîÑ M√É TR√ôNG L·∫∂P ({len(analysis['duplicate_codes'])})
C√°c m√£ c√≥ nhi·ªÅu h√¨nh ·∫£nh:

"""
        for code, images_list in list(analysis['duplicate_codes'].items())[:10]:
            report_content += f"**{code}** ({len(images_list)} h√¨nh ·∫£nh):\n"
            for img in images_list:
                report_content += f"   ‚Ä¢ {img['display_name']}\n"
                report_content += f"     üîó {img['url']}\n"
            report_content += "\n"
    
    # Unmapped images
    if analysis['unmapped_images']:
        report_content += f"""## ‚ùì H√åNH ·∫¢NH CH∆ØA MAP ({len(analysis['unmapped_images'])})
C√°c h√¨nh ·∫£nh kh√¥ng kh·ªõp v·ªõi s·∫£n ph·∫©m n√†o:

"""
        for i, img in enumerate(analysis['unmapped_images'][:15], 1):
            report_content += f"{i}. **{img['display_name']}**\n"
            report_content += f"   üìù M√£ tr√≠ch xu·∫•t: {img['extracted_code']}\n"
            report_content += f"   üîó {img['url']}\n\n"
    
    # Fabrics without images
    report_content += f"""## üì∑ S·∫¢N PH·∫®M CH∆ØA C√ì H√åNH ({len(analysis['fabric_without_images'])})
C√°c s·∫£n ph·∫©m trong database ch∆∞a c√≥ h√¨nh ·∫£nh:

"""
    for i, fabric in enumerate(analysis['fabric_without_images'][:20], 1):
        report_content += f"{i}. **{fabric['code']}** - {fabric['name'][:50]}...\n"
    
    if len(analysis['fabric_without_images']) > 20:
        report_content += f"... v√† {len(analysis['fabric_without_images']) - 20} s·∫£n ph·∫©m kh√°c\n"
    
    report_content += f"""

## üìã K·∫æ HO·∫†CH MAPPING

### üéØ ∆Øu ti√™n 1: Exact Matches
- **{len([m for m in analysis['exact_matches'] if not m['has_existing_image']])} s·∫£n ph·∫©m** c√≥ h√¨nh exact match nh∆∞ng ch∆∞a ƒë∆∞·ª£c map
- **H√†nh ƒë·ªông:** T·ª± ƒë·ªông map ngay l·∫≠p t·ª©c

### ‚úèÔ∏è ∆Øu ti√™n 2: H√¨nh ·∫£nh Edited
- **{len(analysis['edited_images'])} h√¨nh ·∫£nh** c√≥ "edited" trong t√™n
- **H√†nh ƒë·ªông:** Xem x√©t th·ªß c√¥ng, c√≥ th·ªÉ l√† phi√™n b·∫£n c·∫£i ti·∫øn

### üîç ∆Øu ti√™n 3: Similar Matches
- **{len(analysis['similar_matches'])} h√¨nh ·∫£nh** c√≥ m√£ t∆∞∆°ng ƒë·ªìng
- **H√†nh ƒë·ªông:** Xem x√©t th·ªß c√¥ng ƒë·ªÉ x√°c nh·∫≠n mapping

### üîÑ ∆Øu ti√™n 4: Duplicate Codes
- **{len(analysis['duplicate_codes'])} m√£** c√≥ nhi·ªÅu h√¨nh ·∫£nh
- **H√†nh ƒë·ªông:** Ch·ªçn h√¨nh ·∫£nh t·ªët nh·∫•t (∆∞u ti√™n edited version)

### üì∑ ∆Øu ti√™n 5: Upload m·ªõi
- **{len(analysis['fabric_without_images'])} s·∫£n ph·∫©m** ch∆∞a c√≥ h√¨nh ·∫£nh
- **H√†nh ƒë·ªông:** C·∫ßn ch·ª•p/upload h√¨nh ·∫£nh m·ªõi

## üìä Th·ªëng k√™ mapping hi·ªán t·∫°i:
- **ƒê√£ c√≥ h√¨nh:** {len([f for f in fabrics if f.get('image')])} s·∫£n ph·∫©m
- **Ch∆∞a c√≥ h√¨nh:** {len([f for f in fabrics if not f.get('image')])} s·∫£n ph·∫©m
- **T·ª∑ l·ªá c√≥ h√¨nh:** {len([f for f in fabrics if f.get('image')])/len(fabrics)*100:.1f}%

---
T·∫°o b·ªüi: audit-cloudinary-images.py
Th·ªùi gian: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
"""
    
    return report_content

def save_detailed_data(analysis, images, fabrics):
    """L∆∞u d·ªØ li·ªáu chi ti·∫øt ƒë·ªÉ x·ª≠ l√Ω sau"""
    
    # L∆∞u analysis data
    analysis_data = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_images': analysis['total_images'],
            'total_fabrics': len(fabrics),
            'exact_matches': len(analysis['exact_matches']),
            'similar_matches': len(analysis['similar_matches']),
            'edited_images': len(analysis['edited_images']),
            'unmapped_images': len(analysis['unmapped_images']),
            'duplicate_codes': len(analysis['duplicate_codes']),
            'fabric_without_images': len(analysis['fabric_without_images'])
        },
        'analysis': analysis
    }
    
    with open('cloudinary-audit-analysis.json', 'w', encoding='utf-8') as f:
        json.dump(analysis_data, f, ensure_ascii=False, indent=2)
    
    print("üíæ ƒê√£ l∆∞u d·ªØ li·ªáu chi ti·∫øt: cloudinary-audit-analysis.json")

def main():
    print("üöÄ B·∫ÆT ƒê·∫¶U R√Ä SO√ÅT H√åNH ·∫¢NH CLOUDINARY")
    print("="*60)
    
    # 1. L·∫•y t·∫•t c·∫£ h√¨nh ·∫£nh t·ª´ Cloudinary
    images = get_all_cloudinary_images()
    if not images:
        print("‚ùå Kh√¥ng c√≥ h√¨nh ·∫£nh ƒë·ªÉ ph√¢n t√≠ch")
        return
    
    # 2. L·∫•y t·∫•t c·∫£ m√£ v·∫£i t·ª´ database
    fabrics = get_all_fabric_codes()
    if not fabrics:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu fabric ƒë·ªÉ so s√°nh")
        return
    
    # 3. Ph√¢n t√≠ch h√¨nh ·∫£nh
    analysis = analyze_cloudinary_images(images, fabrics)
    
    # 4. T·∫°o b√°o c√°o
    report = create_detailed_report(analysis, images, fabrics)
    
    with open('BAO_CAO_RA_SOAT_CLOUDINARY.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    # 5. L∆∞u d·ªØ li·ªáu chi ti·∫øt
    save_detailed_data(analysis, images, fabrics)
    
    print(f"\nüéâ HO√ÄN T·∫§T R√Ä SO√ÅT!")
    print(f"üìä T·ªïng k·∫øt:")
    print(f"   üì∑ T·ªïng h√¨nh ·∫£nh: {analysis['total_images']}")
    print(f"   ‚úÖ Exact matches: {len(analysis['exact_matches'])}")
    print(f"   ‚úèÔ∏è H√¨nh edited: {len(analysis['edited_images'])}")
    print(f"   üîç Similar matches: {len(analysis['similar_matches'])}")
    print(f"   üîÑ M√£ tr√πng l·∫∑p: {len(analysis['duplicate_codes'])}")
    print(f"   ‚ùì Ch∆∞a map: {len(analysis['unmapped_images'])}")
    print(f"   üì∑ S·∫£n ph·∫©m ch∆∞a c√≥ h√¨nh: {len(analysis['fabric_without_images'])}")
    
    print(f"\nüìÅ Files ƒë√£ t·∫°o:")
    print(f"   üìã BAO_CAO_RA_SOAT_CLOUDINARY.md - B√°o c√°o chi ti·∫øt")
    print(f"   üíæ cloudinary-audit-analysis.json - D·ªØ li·ªáu ph√¢n t√≠ch")

if __name__ == "__main__":
    main()
