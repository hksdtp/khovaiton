#!/usr/bin/env python3
"""
Script thá»±c thi mapping Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a
Äiá»u chá»‰nh thuáº­t toÃ¡n Ä‘á»ƒ cÃ³ nhiá»u HIGH confidence matches hÆ¡n
"""

import json
import urllib.request
import urllib.parse
import re
import difflib
from datetime import datetime
from pathlib import Path

# Supabase configuration
SUPABASE_URL = 'https://zgrfqkytbmahxcbgpkxx.supabase.co'
SUPABASE_ANON_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InpncmZxa3l0Ym1haHhjYmdwa3h4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDYxNjI1MTAsImV4cCI6MjA2MTczODUxMH0.a6giZZFMrj6jBhLip3ShOFCyTHt5dbe31UDGCECh0Zs'

def supabase_request(method, endpoint, data=None):
    """Thá»±c hiá»‡n request Ä‘áº¿n Supabase API"""
    url = f"{SUPABASE_URL}/rest/v1/{endpoint}"
    
    headers = {
        'apikey': SUPABASE_ANON_KEY,
        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',
        'Content-Type': 'application/json',
        'Prefer': 'return=minimal'
    }
    
    try:
        if data:
            data_bytes = json.dumps(data).encode('utf-8')
            req = urllib.request.Request(url, data=data_bytes, headers=headers, method=method)
        else:
            req = urllib.request.Request(url, headers=headers, method=method)
        
        with urllib.request.urlopen(req) as response:
            return response.getcode(), response.read().decode('utf-8')
            
    except urllib.error.HTTPError as e:
        return e.code, e.read().decode('utf-8')
    except Exception as e:
        return 0, str(e)

def load_analysis_data():
    """Load dá»¯ liá»‡u phÃ¢n tÃ­ch"""
    try:
        with open('comprehensive-mapping-analysis.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… ÄÃ£ load dá»¯ liá»‡u phÃ¢n tÃ­ch")
        return data['analysis_results']
        
    except Exception as e:
        print(f"âŒ Lá»—i load dá»¯ liá»‡u: {e}")
        return None

def normalize_code_for_exact_match(code):
    """Chuáº©n hÃ³a mÃ£ Ä‘á»ƒ so sÃ¡nh exact match"""
    if not code:
        return ""
    
    # Chuyá»ƒn vá» uppercase vÃ  loáº¡i bá» khoáº£ng tráº¯ng
    normalized = str(code).upper().strip()
    
    # Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t nhÆ°ng giá»¯ láº¡i dáº¥u gáº¡ch ngang
    normalized = re.sub(r'[^\w\-]', '', normalized)
    
    return normalized

def is_exact_match(product_code, image_name):
    """Kiá»ƒm tra exact match vá»›i tiÃªu chÃ­ lá»ng hÆ¡n"""
    product_norm = normalize_code_for_exact_match(product_code)
    
    # TrÃ­ch xuáº¥t mÃ£ tá»« tÃªn hÃ¬nh áº£nh
    image_norm = normalize_code_for_exact_match(image_name)
    
    # Loáº¡i bá» prefix fabrics/
    if image_norm.startswith('FABRICS'):
        image_norm = image_norm[7:]
    
    # Loáº¡i bá» suffix _edited, _copy, v.v.
    image_norm = re.sub(r'_EDITED.*$', '', image_norm)
    image_norm = re.sub(r'_COPY.*$', '', image_norm)
    image_norm = re.sub(r'_V\d+.*$', '', image_norm)
    image_norm = re.sub(r'_[A-Z0-9]{6,}$', '', image_norm)  # Random suffix
    
    # Exact match
    if product_norm == image_norm:
        return True
    
    # Substring match (má»™t trong hai chá»©a cÃ¡i kia)
    if len(product_norm) >= 4 and len(image_norm) >= 4:
        if product_norm in image_norm or image_norm in product_norm:
            return True
    
    return False

def calculate_enhanced_confidence(product, match_data):
    """TÃ­nh confidence Ä‘Æ°á»£c cáº£i tiáº¿n"""
    product_code = product['code']
    image = match_data['image']
    
    base_confidence = match_data['confidence']
    
    # Bonus factors
    bonus = 0
    
    # 1. Exact match bonus
    if is_exact_match(product_code, image['display_name']):
        bonus += 0.3
    elif is_exact_match(product_code, image.get('extracted_code', '')):
        bonus += 0.25
    elif is_exact_match(product_code, image['public_id']):
        bonus += 0.2
    
    # 2. Edited image bonus (cháº¥t lÆ°á»£ng cao)
    if 'edited' in image['display_name'].lower():
        bonus += 0.15
    
    # 3. Type bonus
    if match_data['type'] == 'exact_match':
        bonus += 0.2
    elif match_data['type'] == 'edited_image':
        bonus += 0.1
    
    # 4. Length similarity bonus
    product_len = len(normalize_code_for_exact_match(product_code))
    image_len = len(normalize_code_for_exact_match(image['display_name']))
    
    if abs(product_len - image_len) <= 2:  # Äá»™ dÃ i tÆ°Æ¡ng tá»±
        bonus += 0.05
    
    # 5. Sequence similarity bonus
    similarity = difflib.SequenceMatcher(
        None, 
        normalize_code_for_exact_match(product_code),
        normalize_code_for_exact_match(image['display_name'])
    ).ratio()
    
    if similarity >= 0.8:
        bonus += 0.1
    
    final_confidence = min(1.0, base_confidence + bonus)
    
    return final_confidence

def recategorize_mappings(analysis_results):
    """PhÃ¢n loáº¡i láº¡i mappings vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n"""
    print("ğŸ”„ Äang phÃ¢n loáº¡i láº¡i mappings vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n...")
    
    new_categorization = {
        'high_confidence': [],
        'medium_confidence': [],
        'low_confidence': [],
        'no_matches': analysis_results['no_matches'],
        'statistics': {
            'total_products': analysis_results['statistics']['total_products'],
            'high_confidence_count': 0,
            'medium_confidence_count': 0,
            'low_confidence_count': 0,
            'without_matches': len(analysis_results['no_matches'])
        }
    }
    
    # Xá»­ lÃ½ táº¥t cáº£ mappings
    all_mappings = (
        analysis_results['high_confidence'] + 
        analysis_results['medium_confidence'] + 
        analysis_results['low_confidence']
    )
    
    for mapping in all_mappings:
        product = mapping['product']
        best_match = mapping['best_match']
        
        # TÃ­nh láº¡i confidence
        enhanced_confidence = calculate_enhanced_confidence(product, best_match)
        
        # Cáº­p nháº­t confidence
        best_match['confidence'] = enhanced_confidence
        mapping['best_match'] = best_match
        
        # PhÃ¢n loáº¡i láº¡i
        if enhanced_confidence >= 0.85:  # Giáº£m threshold cho HIGH
            new_categorization['high_confidence'].append(mapping)
            new_categorization['statistics']['high_confidence_count'] += 1
        elif enhanced_confidence >= 0.7:  # Giáº£m threshold cho MEDIUM
            new_categorization['medium_confidence'].append(mapping)
            new_categorization['statistics']['medium_confidence_count'] += 1
        else:
            new_categorization['low_confidence'].append(mapping)
            new_categorization['statistics']['low_confidence_count'] += 1
    
    # Sáº¯p xáº¿p theo confidence
    new_categorization['high_confidence'].sort(key=lambda x: x['best_match']['confidence'], reverse=True)
    new_categorization['medium_confidence'].sort(key=lambda x: x['best_match']['confidence'], reverse=True)
    new_categorization['low_confidence'].sort(key=lambda x: x['best_match']['confidence'], reverse=True)
    
    return new_categorization

def update_fabric_image(fabric_id, image_url):
    """Cáº­p nháº­t hÃ¬nh áº£nh cho fabric"""
    update_data = {
        'image': image_url,
        'updated_at': datetime.now().isoformat()
    }
    
    status_code, response = supabase_request('PATCH', f'fabrics?id=eq.{fabric_id}', update_data)
    
    return status_code in [200, 204]

def execute_high_confidence_mappings(mappings):
    """Thá»±c thi mappings cÃ³ confidence cao"""
    print(f"ğŸ¯ Äang thá»±c thi {len(mappings)} HIGH confidence mappings...")
    
    success_count = 0
    error_count = 0
    results = []
    
    for i, mapping in enumerate(mappings):
        product = mapping['product']
        match = mapping['best_match']
        
        print(f"   ğŸ“ {i+1}/{len(mappings)}: {product['code']} â†’ {match['image']['display_name']}")
        print(f"      ğŸ“Š Confidence: {match['confidence']:.1%}")
        
        # Thá»±c hiá»‡n mapping
        if update_fabric_image(product['id'], match['image']['url']):
            success_count += 1
            print(f"      âœ… ThÃ nh cÃ´ng")
            
            results.append({
                'product_code': product['code'],
                'product_name': product['name'],
                'image_url': match['image']['url'],
                'image_display_name': match['image']['display_name'],
                'confidence': match['confidence'],
                'type': match['type'],
                'status': 'success'
            })
        else:
            error_count += 1
            print(f"      âŒ Lá»—i")
            
            results.append({
                'product_code': product['code'],
                'product_name': product['name'],
                'image_url': match['image']['url'],
                'image_display_name': match['image']['display_name'],
                'confidence': match['confidence'],
                'type': match['type'],
                'status': 'error'
            })
    
    print(f"\nğŸ“Š Káº¿t quáº£ HIGH confidence mapping:")
    print(f"   âœ… ThÃ nh cÃ´ng: {success_count}")
    print(f"   âŒ Lá»—i: {error_count}")
    
    return results

def execute_medium_confidence_mappings(mappings, auto_execute=False):
    """Thá»±c thi mappings cÃ³ confidence trung bÃ¬nh"""
    print(f"ğŸ” Xá»­ lÃ½ {len(mappings)} MEDIUM confidence mappings...")
    
    if not auto_execute:
        print("ğŸ“‹ Danh sÃ¡ch MEDIUM confidence mappings Ä‘á»ƒ xem xÃ©t:")
        for i, mapping in enumerate(mappings[:10]):  # Hiá»ƒn thá»‹ top 10
            product = mapping['product']
            match = mapping['best_match']
            
            print(f"   {i+1}. {product['code']} â†’ {match['image']['display_name']}")
            print(f"      ğŸ“Š Confidence: {match['confidence']:.1%}")
            print(f"      ğŸ”— {match['image']['url']}")
        
        if len(mappings) > 10:
            print(f"   ... vÃ  {len(mappings) - 10} mappings khÃ¡c")
        
        confirm = input(f"\nğŸ”„ Báº¡n cÃ³ muá»‘n auto-execute {len(mappings)} MEDIUM mappings? (y/N): ")
        auto_execute = confirm.lower() == 'y'
    
    if auto_execute:
        return execute_high_confidence_mappings(mappings)  # Sá»­ dá»¥ng cÃ¹ng logic
    else:
        print("â¸ï¸  Bá» qua MEDIUM confidence mappings")
        return []

def create_execution_report(high_results, medium_results, new_stats):
    """Táº¡o bÃ¡o cÃ¡o thá»±c thi"""
    
    total_mapped = len(high_results) + len(medium_results)
    success_count = len([r for r in high_results + medium_results if r['status'] == 'success'])
    
    current_with_images = 120  # TrÆ°á»›c khi mapping
    new_with_images = current_with_images + success_count
    new_coverage = (new_with_images / 332) * 100
    
    report_content = f"""# ğŸ“Š BÃO CÃO THá»°C THI MAPPING Tá»I Æ¯U

## ğŸ“ˆ Káº¿t quáº£ thá»±c thi:
- **HIGH confidence mappings:** {len(high_results)} ({len([r for r in high_results if r['status'] == 'success'])} thÃ nh cÃ´ng)
- **MEDIUM confidence mappings:** {len(medium_results)} ({len([r for r in medium_results if r['status'] == 'success'])} thÃ nh cÃ´ng)
- **Tá»•ng mapped:** {success_count}/{total_mapped}
- **Tá»· lá»‡ thÃ nh cÃ´ng:** {(success_count/total_mapped*100) if total_mapped > 0 else 0:.1f}%

## ğŸ“Š Coverage sau mapping:
- **TrÆ°á»›c mapping:** 36.1% (120/332)
- **Sau mapping:** {new_coverage:.1f}% ({new_with_images}/332)
- **TÄƒng thÃªm:** +{success_count} sáº£n pháº©m
- **Má»¥c tiÃªu 60%:** {'âœ… Äáº T ÄÆ¯á»¢C' if new_coverage >= 60 else f'âŒ Cáº¦N THÃŠM {int(332*0.6 - new_with_images)} sáº£n pháº©m'}

## âœ… CHI TIáº¾T MAPPINGS THÃ€NH CÃ”NG

### ğŸ¯ HIGH Confidence Mappings
"""
    
    high_success = [r for r in high_results if r['status'] == 'success']
    for i, result in enumerate(high_success, 1):
        report_content += f"{i}. **{result['product_code']}** - {result['product_name'][:50]}...\n"
        report_content += f"   ğŸ–¼ï¸ {result['image_display_name']}\n"
        report_content += f"   ğŸ“Š Confidence: {result['confidence']:.1%} | Type: {result['type']}\n"
        report_content += f"   ğŸ”— {result['image_url']}\n\n"
    
    if medium_results:
        medium_success = [r for r in medium_results if r['status'] == 'success']
        report_content += f"### ğŸ” MEDIUM Confidence Mappings\n\n"
        
        for i, result in enumerate(medium_success, 1):
            report_content += f"{i}. **{result['product_code']}** - {result['product_name'][:50]}...\n"
            report_content += f"   ğŸ–¼ï¸ {result['image_display_name']}\n"
            report_content += f"   ğŸ“Š Confidence: {result['confidence']:.1%} | Type: {result['type']}\n"
            report_content += f"   ğŸ”— {result['image_url']}\n\n"
    
    # Thá»‘ng kÃª cÃ²n láº¡i
    remaining_high = new_stats['high_confidence_count'] - len(high_results)
    remaining_medium = new_stats['medium_confidence_count'] - len(medium_results)
    remaining_low = new_stats['low_confidence_count']
    remaining_no_match = new_stats['without_matches']
    
    report_content += f"""## ğŸ“‹ CÃ”NG VIá»†C CÃ’N Láº I

### ğŸ¯ CÃ³ thá»ƒ mapping thÃªm:
- **HIGH confidence:** {remaining_high} sáº£n pháº©m (auto mapping)
- **MEDIUM confidence:** {remaining_medium} sáº£n pháº©m (manual review)
- **LOW confidence:** {remaining_low} sáº£n pháº©m (detailed check)

### ğŸ“· Cáº§n upload hÃ¬nh má»›i:
- **KhÃ´ng cÃ³ matches:** {remaining_no_match} sáº£n pháº©m

## ğŸ¯ Káº¿ hoáº¡ch tiáº¿p theo:
1. **Mapping thÃªm HIGH confidence:** {remaining_high} sáº£n pháº©m
2. **Review MEDIUM confidence:** {remaining_medium} sáº£n pháº©m  
3. **Check LOW confidence:** {remaining_low} sáº£n pháº©m
4. **Upload hÃ¬nh má»›i:** {remaining_no_match} sáº£n pháº©m

## ğŸ“Š Dá»± bÃ¡o cuá»‘i cÃ¹ng:
- **Náº¿u mapping háº¿t HIGH+MEDIUM:** {((120 + new_stats['high_confidence_count'] + new_stats['medium_confidence_count'])/332*100):.1f}%
- **Äá»ƒ Ä‘áº¡t 60% cáº§n thÃªm:** {max(0, int(332*0.6) - 120 - new_stats['high_confidence_count'] - new_stats['medium_confidence_count'])} sáº£n pháº©m

---
Táº¡o bá»Ÿi: optimized-mapping-executor.py
Thá»i gian: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}
"""
    
    return report_content

def main():
    print("ğŸš€ Báº®T Äáº¦U THá»°C THI MAPPING Tá»I Æ¯U")
    print("="*60)
    
    # 1. Load dá»¯ liá»‡u phÃ¢n tÃ­ch
    analysis_results = load_analysis_data()
    if not analysis_results:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u phÃ¢n tÃ­ch")
        return
    
    # 2. PhÃ¢n loáº¡i láº¡i vá»›i thuáº­t toÃ¡n cáº£i tiáº¿n
    new_categorization = recategorize_mappings(analysis_results)
    
    # 3. Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n loáº¡i má»›i
    stats = new_categorization['statistics']
    print(f"\nğŸ“Š Káº¿t quáº£ phÃ¢n loáº¡i má»›i:")
    print(f"   ğŸ¯ HIGH confidence: {stats['high_confidence_count']} (â‰¥85%)")
    print(f"   ğŸ” MEDIUM confidence: {stats['medium_confidence_count']} (70-84%)")
    print(f"   âš ï¸  LOW confidence: {stats['low_confidence_count']} (<70%)")
    print(f"   âŒ No matches: {stats['without_matches']}")
    
    potential_new = stats['high_confidence_count'] + stats['medium_confidence_count']
    new_coverage = ((120 + potential_new) / 332) * 100
    
    print(f"\nğŸ¯ Dá»± bÃ¡o coverage:")
    print(f"   ğŸ“ˆ Hiá»‡n táº¡i: 36.1% (120/332)")
    print(f"   ğŸ“ˆ Sau mapping: {new_coverage:.1f}% (+{potential_new})")
    print(f"   ğŸ¯ Má»¥c tiÃªu 60%: {'âœ… Äáº T ÄÆ¯á»¢C' if new_coverage >= 60 else 'âŒ Cáº¦N THÃŠM'}")
    
    if stats['high_confidence_count'] == 0:
        print("\nâš ï¸  KhÃ´ng cÃ³ HIGH confidence mappings Ä‘á»ƒ thá»±c thi")
        return
    
    # 4. XÃ¡c nháº­n thá»±c thi
    confirm = input(f"\nğŸ”„ Báº¡n cÃ³ muá»‘n thá»±c thi {stats['high_confidence_count']} HIGH confidence mappings? (y/N): ")
    
    if confirm.lower() != 'y':
        print("âŒ ÄÃ£ há»§y thá»±c thi")
        return
    
    # 5. Thá»±c thi HIGH confidence mappings
    high_results = execute_high_confidence_mappings(new_categorization['high_confidence'])
    
    # 6. Xá»­ lÃ½ MEDIUM confidence mappings
    medium_results = execute_medium_confidence_mappings(new_categorization['medium_confidence'])
    
    # 7. Táº¡o bÃ¡o cÃ¡o
    report = create_execution_report(high_results, medium_results, stats)
    
    with open('BAO_CAO_THUC_THI_MAPPING.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    # 8. LÆ°u káº¿t quáº£ chi tiáº¿t
    with open('mapping-execution-results.json', 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'high_results': high_results,
            'medium_results': medium_results,
            'new_categorization': new_categorization
        }, f, ensure_ascii=False, indent=2)
    
    # 9. TÃ³m táº¯t káº¿t quáº£
    total_success = len([r for r in high_results + medium_results if r['status'] == 'success'])
    new_total_with_images = 120 + total_success
    final_coverage = (new_total_with_images / 332) * 100
    
    print(f"\nğŸ‰ HOÃ€N Táº¤T THá»°C THI!")
    print(f"   âœ… ÄÃ£ mapping thÃ nh cÃ´ng: {total_success} sáº£n pháº©m")
    print(f"   ğŸ“ˆ Coverage má»›i: {final_coverage:.1f}% ({new_total_with_images}/332)")
    print(f"   ğŸ¯ Má»¥c tiÃªu 60%: {'âœ… Äáº T ÄÆ¯á»¢C' if final_coverage >= 60 else 'âŒ Cáº¦N THÃŠM'}")
    
    print(f"\nğŸ“ Files Ä‘Ã£ táº¡o:")
    print(f"   ğŸ“‹ BAO_CAO_THUC_THI_MAPPING.md")
    print(f"   ğŸ’¾ mapping-execution-results.json")
    
    print(f"\nğŸ’¡ BÆ°á»›c tiáº¿p theo: Restart web app Ä‘á»ƒ tháº¥y hÃ¬nh áº£nh má»›i!")

if __name__ == "__main__":
    main()
